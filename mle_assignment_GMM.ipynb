{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ddaf923-f7eb-408c-ae66-4c446411e034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.mixture import BayesianGaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "195c4b4e-cf62-4ce9-9ed9-d1e34c85ceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformer():\n",
    "    \n",
    "    \"\"\"\n",
    "    Transformer class responsible for processing data to train the CTABGANSynthesizer model\n",
    "    \n",
    "    Variables:\n",
    "    1) train_data -> input dataframe \n",
    "    2) categorical_list -> list of categorical columns\n",
    "    3) mixed_dict -> dictionary of mixed columns\n",
    "    4) n_clusters -> number of modes to fit bayesian gaussian mixture (bgm) model\n",
    "    5) eps -> threshold for ignoring less prominent modes in the mixture model \n",
    "    6) ordering -> stores original ordering for modes of numeric columns\n",
    "    7) output_info -> stores dimension and output activations of columns (i.e., tanh for numeric, softmax for categorical)\n",
    "    8) output_dim -> stores the final column width of the transformed data\n",
    "    9) components -> stores the valid modes used by numeric columns\n",
    "    10) filter_arr -> stores valid indices of continuous component in mixed columns\n",
    "    11) meta -> stores column information corresponding to different data types i.e., categorical/mixed/numerical\n",
    "\n",
    "\n",
    "    Methods:\n",
    "    1) __init__() -> initializes transformer object and computes meta information of columns\n",
    "    2) get_metadata() -> builds an inventory of individual columns and stores their relevant properties\n",
    "    3) fit() -> fits the required bgm models to process the input data\n",
    "    4) transform() -> executes the transformation required to train the model\n",
    "    5) inverse_transform() -> executes the reverse transformation on data generated from the model\n",
    "    \n",
    "    \"\"\"    \n",
    "    \n",
    "    def __init__(self, train_data=pd.DataFrame, categorical_list=[], mixed_dict={}, n_clusters=10, eps=0.005):\n",
    "        \n",
    "        self.meta = None\n",
    "        self.train_data = train_data\n",
    "        self.categorical_columns= categorical_list\n",
    "        self.mixed_columns= mixed_dict\n",
    "        self.n_clusters = n_clusters\n",
    "        self.eps = eps\n",
    "        self.ordering = []\n",
    "        self.output_info = []\n",
    "        self.output_dim = 0\n",
    "        self.components = []\n",
    "        self.filter_arr = []\n",
    "        self.meta = self.get_metadata()\n",
    "        \n",
    "    def get_metadata(self):\n",
    "        \n",
    "        meta = []\n",
    "    \n",
    "        for index in range(self.train_data.shape[1]):\n",
    "            column = self.train_data.iloc[:,index]\n",
    "            if index in self.categorical_columns:\n",
    "                mapper = column.value_counts().index.tolist()\n",
    "                meta.append({\n",
    "                        \"name\": index,\n",
    "                        \"type\": \"categorical\",\n",
    "                        \"size\": len(mapper),\n",
    "                        \"i2s\": mapper\n",
    "                })\n",
    "            elif index in self.mixed_columns.keys():\n",
    "                meta.append({\n",
    "                    \"name\": index,\n",
    "                    \"type\": \"mixed\",\n",
    "                    \"min\": column.min(),\n",
    "                    \"max\": column.max(),\n",
    "                    \"modal\": self.mixed_columns[index]\n",
    "                })\n",
    "            else:\n",
    "                meta.append({\n",
    "                    \"name\": index,\n",
    "                    \"type\": \"continuous\",\n",
    "                    \"min\": column.min(),\n",
    "                    \"max\": column.max(),\n",
    "                })            \n",
    "\n",
    "        return meta\n",
    "\n",
    "    def fit(self):\n",
    "        \n",
    "        data = self.train_data.values\n",
    "        \n",
    "        # stores the corresponding bgm models for processing numeric data\n",
    "        model = []\n",
    "        \n",
    "        # iterating through column information\n",
    "        for id_, info in enumerate(self.meta):\n",
    "            if info['type'] == \"continuous\":\n",
    "                # fitting bgm model  \n",
    "                gm = BayesianGaussianMixture(\n",
    "                    n_components = self.n_clusters, \n",
    "                    weight_concentration_prior_type='dirichlet_process',\n",
    "                    weight_concentration_prior=0.001, # lower values result in lesser modes being active\n",
    "                    max_iter=100,n_init=1, random_state=42)\n",
    "                gm.fit(data[:, id_].reshape([-1, 1]))\n",
    "                model.append(gm)\n",
    "                # keeping only relevant modes that have higher weight than eps and are used to fit the data\n",
    "                old_comp = gm.weights_ > self.eps\n",
    "                mode_freq = (pd.Series(gm.predict(data[:, id_].reshape([-1, 1]))).value_counts().keys())\n",
    "                comp = []\n",
    "                for i in range(self.n_clusters):\n",
    "                    if (i in (mode_freq)) & old_comp[i]:\n",
    "                        comp.append(True)\n",
    "                    else:\n",
    "                        comp.append(False)\n",
    "                self.components.append(comp) \n",
    "                self.output_info += [(1, 'tanh'), (np.sum(comp), 'softmax')]\n",
    "                self.output_dim += 1 + np.sum(comp)\n",
    "                \n",
    "            elif info['type'] == \"mixed\":\n",
    "                \n",
    "                # in case of mixed columns, two bgm models are used\n",
    "                gm1 = BayesianGaussianMixture(\n",
    "                    self.n_clusters, \n",
    "                    weight_concentration_prior_type='dirichlet_process',\n",
    "                    weight_concentration_prior=0.001, max_iter=100,\n",
    "                    n_init=1,random_state=42)\n",
    "                gm2 = BayesianGaussianMixture(\n",
    "                    self.n_clusters,\n",
    "                    weight_concentration_prior_type='dirichlet_process',\n",
    "                    weight_concentration_prior=0.001, max_iter=100,\n",
    "                    n_init=1,random_state=42)\n",
    "                \n",
    "                # first bgm model is fit to the entire data only for the purposes of obtaining a normalized value of any particular categorical mode\n",
    "                gm1.fit(data[:, id_].reshape([-1, 1]))\n",
    "                \n",
    "                # main bgm model used to fit the continuous component and serves the same purpose as with purely numeric columns\n",
    "                filter_arr = []\n",
    "                for element in data[:, id_]:\n",
    "                    if element not in info['modal']:\n",
    "                        filter_arr.append(True)\n",
    "                    else:\n",
    "                        filter_arr.append(False)\n",
    "                self.filter_arr.append(filter_arr)\n",
    "                \n",
    "                gm2.fit(data[:, id_][filter_arr].reshape([-1, 1]))\n",
    "                \n",
    "                model.append((gm1,gm2))\n",
    "                \n",
    "                # similarly keeping only relevant modes with higher weight than eps and are used to fit strictly continuous data \n",
    "                old_comp = gm2.weights_ > self.eps\n",
    "                mode_freq = (pd.Series(gm2.predict(data[:, id_][filter_arr].reshape([-1, 1]))).value_counts().keys())  \n",
    "                comp = []\n",
    "                  \n",
    "                for i in range(self.n_clusters):\n",
    "                    if (i in (mode_freq)) & old_comp[i]:\n",
    "                        comp.append(True)\n",
    "                    else:\n",
    "                        comp.append(False)\n",
    "\n",
    "                self.components.append(comp)\n",
    "                \n",
    "                # modes of the categorical component are appended to modes produced by the main bgm model\n",
    "                self.output_info += [(1, 'tanh'), (np.sum(comp) + len(info['modal']), 'softmax')]\n",
    "                self.output_dim += 1 + np.sum(comp) + len(info['modal'])\n",
    "            \n",
    "            else:\n",
    "                # in case of categorical columns, bgm model is ignored\n",
    "                model.append(None)\n",
    "                self.components.append(None)\n",
    "                self.output_info += [(info['size'], 'softmax')]\n",
    "                self.output_dim += info['size']\n",
    "        \n",
    "        self.model = model\n",
    "\n",
    "    def transform(self, data):\n",
    "        \n",
    "        # stores the transformed values\n",
    "        values = []\n",
    "\n",
    "        # used for accessing filter_arr for transforming mixed columns\n",
    "        mixed_counter = 0\n",
    "        \n",
    "        # iterating through column information\n",
    "        for id_, info in enumerate(self.meta):\n",
    "            current = data[:, id_]\n",
    "            if info['type'] == \"continuous\":\n",
    "                # mode-specific normalization occurs here\n",
    "                current = current.reshape([-1, 1])\n",
    "                # means and stds of the modes are obtained from the corresponding fitted bgm model\n",
    "                means = self.model[id_].means_.reshape((1, self.n_clusters))\n",
    "                stds = np.sqrt(self.model[id_].covariances_).reshape((1, self.n_clusters))\n",
    "                # values are then normalized and stored for all modes\n",
    "                features = np.empty(shape=(len(current),self.n_clusters))\n",
    "                # note 4 is a multiplier to ensure values lie between -1 to 1 but this is not always guaranteed\n",
    "                features = (current - means) / (4 * stds) \n",
    "\n",
    "                # number of distict modes\n",
    "                n_opts = sum(self.components[id_])                \n",
    "                # storing the mode for each data point by sampling from the probability mass distribution across all modes based on fitted bgm model \n",
    "                opt_sel = np.zeros(len(data), dtype='int')\n",
    "                probs = self.model[id_].predict_proba(current.reshape([-1, 1]))\n",
    "                probs = probs[:, self.components[id_]]\n",
    "                for i in range(len(data)):\n",
    "                    pp = probs[i] + 1e-6\n",
    "                    pp = pp / sum(pp)\n",
    "                    opt_sel[i] = np.random.choice(np.arange(n_opts), p=pp)\n",
    "                \n",
    "                # creating a one-hot-encoding for the corresponding selected modes\n",
    "                probs_onehot = np.zeros_like(probs)\n",
    "                probs_onehot[np.arange(len(probs)), opt_sel] = 1\n",
    "\n",
    "                # obtaining the normalized values based on the appropriately selected mode and clipping to ensure values are within (-1,1)\n",
    "                idx = np.arange((len(features)))\n",
    "                features = features[:, self.components[id_]]\n",
    "                features = features[idx, opt_sel].reshape([-1, 1])\n",
    "                features = np.clip(features, -.99, .99) \n",
    "                \n",
    "                # re-ordering the one-hot-encoding of modes in descending order as per their frequency of being selected\n",
    "                re_ordered_phot = np.zeros_like(probs_onehot)  \n",
    "                col_sums = probs_onehot.sum(axis=0)\n",
    "                n = probs_onehot.shape[1]\n",
    "                largest_indices = np.argsort(-1*col_sums)[:n]\n",
    "                for id,val in enumerate(largest_indices):\n",
    "                    re_ordered_phot[:,id] = probs_onehot[:,val]\n",
    "                \n",
    "                # storing the original ordering for invoking inverse transform\n",
    "                self.ordering.append(largest_indices)\n",
    "                \n",
    "                # storing transformed numeric column represented as normalized values and corresponding modes \n",
    "                values += [features, re_ordered_phot]\n",
    "                  \n",
    "            elif info['type'] == \"mixed\":\n",
    "                \n",
    "                # means and standard deviation of modes obtained from the first fitted bgm model\n",
    "                means_0 = self.model[id_][0].means_.reshape([-1])\n",
    "                stds_0 = np.sqrt(self.model[id_][0].covariances_).reshape([-1])\n",
    "\n",
    "                # list to store relevant bgm modes for categorical components\n",
    "                zero_std_list = []\n",
    "                \n",
    "                # means and stds needed to normalize relevant categorical components\n",
    "                means_needed = []\n",
    "                stds_needed = []\n",
    "\n",
    "                # obtaining the closest bgm mode to the categorical component\n",
    "                for mode in info['modal']:\n",
    "                    # skipped for mode representing missing values\n",
    "                    if mode!=-9999999:\n",
    "                        dist = []\n",
    "                        for idx,val in enumerate(list(means_0.flatten())):\n",
    "                            dist.append(abs(mode-val))\n",
    "                        index_min = np.argmin(np.array(dist))\n",
    "                        zero_std_list.append(index_min)\n",
    "                    else: continue\n",
    "\n",
    "                \n",
    "                # stores the appropriate normalized value of categorical modes\n",
    "                mode_vals = []\n",
    "                \n",
    "                # based on the means and stds of the chosen modes for categorical components, their respective values are similarly normalized\n",
    "                for idx in zero_std_list:\n",
    "                    means_needed.append(means_0[idx])\n",
    "                    stds_needed.append(stds_0[idx])\n",
    "               \n",
    "                for i,j,k in zip(info['modal'],means_needed,stds_needed):\n",
    "                    this_val  = np.clip(((i - j) / (4*k)), -.99, .99) \n",
    "                    mode_vals.append(this_val)\n",
    "                \n",
    "                # for categorical modes representing missing values, the normalized value associated is simply 0\n",
    "                if -9999999 in info[\"modal\"]:\n",
    "                    mode_vals.append(0)\n",
    "                \n",
    "                # transforming continuous component of mixed columns similar to purely numeric columns using second fitted bgm model\n",
    "                current = current.reshape([-1, 1])\n",
    "                filter_arr = self.filter_arr[mixed_counter]\n",
    "                current = current[filter_arr]\n",
    "    \n",
    "                means = self.model[id_][1].means_.reshape((1, self.n_clusters))\n",
    "                stds = np.sqrt(self.model[id_][1].covariances_).reshape((1, self.n_clusters))\n",
    "                \n",
    "                features = np.empty(shape=(len(current),self.n_clusters))\n",
    "                features = (current - means) / (4 * stds)\n",
    "                \n",
    "                n_opts = sum(self.components[id_]) \n",
    "                probs = self.model[id_][1].predict_proba(current.reshape([-1, 1]))\n",
    "                probs = probs[:, self.components[id_]]\n",
    "                \n",
    "                opt_sel = np.zeros(len(current), dtype='int')\n",
    "                for i in range(len(current)):\n",
    "                    pp = probs[i] + 1e-6\n",
    "                    pp = pp / sum(pp)\n",
    "                    opt_sel[i] = np.random.choice(np.arange(n_opts), p=pp)\n",
    "                \n",
    "                idx = np.arange((len(features)))\n",
    "                features = features[:, self.components[id_]]\n",
    "                features = features[idx, opt_sel].reshape([-1, 1])\n",
    "                features = np.clip(features, -.99, .99)\n",
    "                \n",
    "                probs_onehot = np.zeros_like(probs)\n",
    "                probs_onehot[np.arange(len(probs)), opt_sel] = 1\n",
    "                \n",
    "                # additional modes are appended to represent categorical component\n",
    "                extra_bits = np.zeros([len(current), len(info['modal'])])\n",
    "                temp_probs_onehot = np.concatenate([extra_bits,probs_onehot], axis = 1)\n",
    "                \n",
    "                # storing the final normalized value and one-hot-encoding of selected modes\n",
    "                final = np.zeros([len(data), 1 + probs_onehot.shape[1] + len(info['modal'])])\n",
    "\n",
    "                # iterates through only the continuous component\n",
    "                features_curser = 0\n",
    "\n",
    "                for idx, val in enumerate(data[:, id_]):\n",
    "                    \n",
    "                    if val in info['modal']:\n",
    "                        # dealing with the modes of categorical component\n",
    "                        category_ = list(map(info['modal'].index, [val]))[0]\n",
    "                        final[idx, 0] = mode_vals[category_]\n",
    "                        final[idx, (category_+1)] = 1\n",
    "                    \n",
    "                    else:\n",
    "                        # dealing with the modes of continuous component\n",
    "                        final[idx, 0] = features[features_curser]\n",
    "                        final[idx, (1+len(info['modal'])):] = temp_probs_onehot[features_curser][len(info['modal']):]\n",
    "                        features_curser = features_curser + 1\n",
    "\n",
    "                # re-ordering the one-hot-encoding of modes in descending order as per their frequency of being selected\n",
    "                just_onehot = final[:,1:]\n",
    "                re_ordered_jhot= np.zeros_like(just_onehot)\n",
    "                n = just_onehot.shape[1]\n",
    "                col_sums = just_onehot.sum(axis=0)\n",
    "                largest_indices = np.argsort(-1*col_sums)[:n]\n",
    "                \n",
    "                for id,val in enumerate(largest_indices):\n",
    "                      re_ordered_jhot[:,id] = just_onehot[:,val]\n",
    "                \n",
    "                final_features = final[:,0].reshape([-1, 1])\n",
    "                \n",
    "                # storing the original ordering for invoking inverse transform\n",
    "                self.ordering.append(largest_indices)\n",
    "                \n",
    "                values += [final_features, re_ordered_jhot]\n",
    "                \n",
    "                mixed_counter = mixed_counter + 1\n",
    "    \n",
    "            else:\n",
    "                # for categorical columns, standard one-hot-encoding is applied where categories are in descending order of frequency by default\n",
    "                self.ordering.append(None)\n",
    "                col_t = np.zeros([len(data), info['size']])\n",
    "                idx = list(map(info['i2s'].index, current))\n",
    "                col_t[np.arange(len(data)), idx] = 1\n",
    "                values.append(col_t)\n",
    "                \n",
    "        return np.concatenate(values, axis=1)\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        \n",
    "        # stores the final inverse transformed generated data \n",
    "        data_t = np.zeros([len(data), len(self.meta)])\n",
    "        \n",
    "        # used to iterate through the columns of the raw generated data\n",
    "        st = 0\n",
    "\n",
    "        # iterating through original column information\n",
    "        for id_, info in enumerate(self.meta):\n",
    "            if info['type'] == \"continuous\":\n",
    "                \n",
    "                # obtaining the generated normalized values and clipping for stability\n",
    "                u = data[:, st]\n",
    "                u = np.clip(u, -1, 1)\n",
    "                \n",
    "                # obtaining the one-hot-encoding of the modes representing the normalized values\n",
    "                v = data[:, st + 1:st + 1 + np.sum(self.components[id_])]\n",
    "                \n",
    "                # re-ordering the modes as per their original ordering\n",
    "                order = self.ordering[id_] \n",
    "                v_re_ordered = np.zeros_like(v)\n",
    "                for id,val in enumerate(order):\n",
    "                    v_re_ordered[:,val] = v[:,id]\n",
    "                v = v_re_ordered\n",
    "\n",
    "                # ensuring un-used modes are represented with -100 such that they can be ignored when computing argmax\n",
    "                v_t = np.ones((data.shape[0], self.n_clusters)) * -100\n",
    "                v_t[:, self.components[id_]] = v\n",
    "                v = v_t\n",
    "                \n",
    "                # obtaining approriate means and stds as per the appropriately selected mode for each data point based on fitted bgm model\n",
    "                means = self.model[id_].means_.reshape([-1])\n",
    "                stds = np.sqrt(self.model[id_].covariances_).reshape([-1])\n",
    "                p_argmax = np.argmax(v, axis=1)\n",
    "                std_t = stds[p_argmax]\n",
    "                mean_t = means[p_argmax]\n",
    "                \n",
    "                # executing the inverse transformation \n",
    "                tmp = u * 4 * std_t + mean_t\n",
    "                \n",
    "                data_t[:, id_] = tmp\n",
    "                \n",
    "                # moving to the next set of columns in the raw generated data in correspondance to original column information\n",
    "                st += 1 + np.sum(self.components[id_])\n",
    "                \n",
    "            elif info['type'] == \"mixed\":\n",
    "                \n",
    "                # obtaining the generated normalized values and corresponding modes\n",
    "                u = data[:, st]\n",
    "                u = np.clip(u, -1, 1)\n",
    "                full_v = data[:,(st+1):(st+1)+len(info['modal'])+np.sum(self.components[id_])]\n",
    "                \n",
    "                # re-ordering the modes as per their original ordering\n",
    "                order = self.ordering[id_]\n",
    "                full_v_re_ordered = np.zeros_like(full_v)\n",
    "                for id,val in enumerate(order):\n",
    "                    full_v_re_ordered[:,val] = full_v[:,id]\n",
    "                full_v = full_v_re_ordered                \n",
    "                \n",
    "                # modes of categorical component\n",
    "                mixed_v = full_v[:,:len(info['modal'])]\n",
    "                \n",
    "                # modes of continuous component\n",
    "                v = full_v[:,-np.sum(self.components[id_]):]\n",
    "\n",
    "                # similarly ensuring un-used modes are represented with -100 to be ignored while computing argmax\n",
    "                v_t = np.ones((data.shape[0], self.n_clusters)) * -100\n",
    "                v_t[:, self.components[id_]] = v\n",
    "                v = np.concatenate([mixed_v,v_t], axis=1)       \n",
    "                p_argmax = np.argmax(v, axis=1)\n",
    "\n",
    "                # obtaining the means and stds of the continuous component using second fitted bgm model\n",
    "                means = self.model[id_][1].means_.reshape([-1]) \n",
    "                stds = np.sqrt(self.model[id_][1].covariances_).reshape([-1]) \n",
    "\n",
    "                # used to store the inverse-transformed data points\n",
    "                result = np.zeros_like(u)\n",
    "\n",
    "                for idx in range(len(data)):\n",
    "                    # in case of categorical mode being selected, the mode value itself is simply assigned \n",
    "                    if p_argmax[idx] < len(info['modal']):\n",
    "                        argmax_value = p_argmax[idx]\n",
    "                        result[idx] = float(list(map(info['modal'].__getitem__, [argmax_value]))[0])\n",
    "                    else:\n",
    "                        # in case of continuous mode being selected, similar inverse-transform for purely numeric values is applied\n",
    "                        std_t = stds[(p_argmax[idx]-len(info['modal']))]\n",
    "                        mean_t = means[(p_argmax[idx]-len(info['modal']))]\n",
    "                        result[idx] = u[idx] * 4 * std_t + mean_t\n",
    "            \n",
    "                data_t[:, id_] = result\n",
    "\n",
    "                st += 1 + np.sum(self.components[id_]) + len(info['modal'])\n",
    "                \n",
    "            else:\n",
    "                # reversing one hot encoding back to label encoding for categorical columns \n",
    "                current = data[:, st:st + info['size']]\n",
    "                idx = np.argmax(current, axis=1)\n",
    "                data_t[:, id_] = list(map(info['i2s'].__getitem__, idx))\n",
    "                st += info['size']\n",
    "        return data_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b643c80-9e5a-48bd-be20-f266f4ed8a08",
   "metadata": {},
   "source": [
    "# Improving GMM encoding for continuous value column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb67b62-2b49-4cc5-a2eb-a1d3a086dbf3",
   "metadata": {},
   "source": [
    "Following we give an example of how to use our current gaussian mixture model to encode and decode continuous column. For this test, we have three demands:\n",
    "1. Current test is based on a small dataset. Please scale the code to enable GMM encoding on 1B rows data. This part is actually two sub-tasks (i) read 1B rows data into the algorithm and (ii) scale current GMM method to encode 1B rows data within a reasonable time.\n",
    "2. Properly evaluate the new GMM encoder. Make sure all the values can be inverse transformed. Especially the extreme values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524d927f-89ea-42e6-82b8-6c79bc81188c",
   "metadata": {},
   "source": [
    "## Load data and encode column using gaussian mixture method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fc166af-ea89-4844-80a3-fb6e56d718d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"Credit.csv\")[[\"Amount\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f22e0c44-b7bb-4f42-b832-aa45fc5b248a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>197.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Amount\n",
       "0   14.61\n",
       "1    1.00\n",
       "2  197.04\n",
       "3    1.00\n",
       "4   23.25"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e52c78f2-5e51-4548-9d1f-e1ae7660ef35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/L085691/Library/Python/3.9/lib/python/site-packages/sklearn/mixture/_base.py:270: ConvergenceWarning: Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "transformer = DataTransformer(train_data=train_data)\n",
    "transformer.fit() \n",
    "transformed_train_data = transformer.transform(train_data.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725a2f37-2f1b-45f8-abdb-6d212a9d662b",
   "metadata": {},
   "source": [
    "### Show the encoding for value 14.61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb1a9f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44648112,  1.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.21828724,  1.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.06976221,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.31899799,  1.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.15266779,  0.        ,  1.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.24682926,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8791b6a0-b607-4e86-b8e1-b87817116d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transformed_train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4362ca-7963-4e69-9477-16bf1f06085e",
   "metadata": {},
   "source": [
    "## Inverse transform back the encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ddee28f2-ff90-460e-b835-b8cb76bc0511",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_transformed_train_data = transformer.inverse_transform(transformed_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15757369-273e-4c0a-aecd-96089bf0571f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 14.61],\n",
       "       [  1.  ],\n",
       "       [197.04],\n",
       "       ...,\n",
       "       [ 12.  ],\n",
       "       [ 36.  ],\n",
       "       [108.  ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_transformed_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b1d92dd9-6a21-455b-a378-3962337de387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>197.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Amount\n",
       "0   14.61\n",
       "1    1.00\n",
       "2  197.04\n",
       "3    1.00\n",
       "4   23.25"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(inverse_transformed_train_data, columns=[\"Amount\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008e9e14-b62f-44e8-9994-f205780015cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
